{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adm\\.conda\\envs\\moonshot\\lib\\site-packages\\albumentations\\__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, Literal, Callable, Sequence, Any\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import openpyxl\n",
    "cv2.setNumThreads(0)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import os\n",
    "import lightning.pytorch as pl\n",
    "from torchmetrics.classification import (\n",
    "    MultilabelAUROC, MultilabelAveragePrecision\n",
    ")\n",
    "import shutil \n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from lightning.pytorch.utilities.types import OptimizerLRScheduler\n",
    "\n",
    "from torchvision.models.resnet import resnet50\n",
    "\n",
    "from moonshot.model import moonshot\n",
    "from moonshot.image_processor import ImageProcessor\n",
    "from moonshot.utils import eval_mode\n",
    "from pathlib import Path\n",
    "from typing import Callable, Sequence, Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.resnet import resnet50\n",
    "from torchvision.datasets import ImageFolder\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import os\n",
    "DEVICE = torch.device('cuda')\n",
    "NUM_WORKERS = 16  # поменяйте на кол-во доступных CPU\n",
    "\n",
    "# укажите полный или относительный путь до файла с весами модели Moonshot\n",
    "MOONSHOT_MODEL_FILEPATH = Path('../vision_model.pt')  # путь до модели, если она лежит в корне репозитория\n",
    "\n",
    "# --- 1. Настройка устройства ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# --- 2. Класс Dataset для DICOM изображений ---\n",
    "class DICOMDataset(Dataset):\n",
    "    def __init__(self, image_paths: Sequence[Path], labels: Sequence[int], transform: Optional[Callable] = None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        dicom_file = pydicom.dcmread(str(self.image_paths[idx]))\n",
    "        img = dicom_file.pixel_array\n",
    "        img = cv2.resize(img, (224, 224))  # Преобразуем размер изображения\n",
    "\n",
    "        # Если изображение ч/б, добавим фиктивный канал\n",
    "        if len(img.shape) == 2:\n",
    "            img = np.expand_dims(img, axis=-1)\n",
    "        \n",
    "        # Преобразуем к формату albumentations\n",
    "        img = np.repeat(img, 3, axis=-1).astype(np.uint8)  # Преобразуем в 3 канала\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)[\"image\"]\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "\n",
    "\n",
    "# --- 3. Аугментации ---\n",
    "transform = A.Compose([\n",
    "    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "# --- 4. Модель ---\n",
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self, num_classes: int = 1):\n",
    "        super().__init__()\n",
    "        self.model = resnet50(pretrained=True)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "# --- 5. Тренировка ---\n",
    "def train_model(model, train_loader, epochs=10, lr=1e-4):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs).squeeze(1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 DICOM files.\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path('D:/ds_clav_fracture_train_good/block_0000_anon/')\n",
    "VINDRCXR_DIRPATH = list(data_dir.rglob(\"*.dcm\"))  # Рекурсивный поиск DICOM файлов\n",
    "\n",
    "destination = \"D:/l\"\n",
    "  \n",
    "for i in range(len(VINDRCXR_DIRPATH)):\n",
    "    dest = shutil.move(VINDRCXR_DIRPATH[i], destination) \n",
    "print(f\"Found {len(VINDRCXR_DIRPATH)} DICOM files.\")\n",
    "VINDRCXR_DIRPATH = \"D:/l\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 DICOM files.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m image_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data_dir\u001b[38;5;241m.\u001b[39mrglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.dcm\u001b[39m\u001b[38;5;124m\"\u001b[39m))  \u001b[38;5;66;03m# Рекурсивный поиск DICOM файлов\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(image_paths)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m DICOM files.\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Проверяем количество файлов\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m dicom_filepath \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_paths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m dicom \u001b[38;5;241m=\u001b[39m pydicom\u001b[38;5;241m.\u001b[39mdcmread(dicom_filepath)\n\u001b[0;32m      6\u001b[0m image \u001b[38;5;241m=\u001b[39m ImageProcessor\u001b[38;5;241m.\u001b[39mpreprocess_dicom(dicom)\n",
      "File \u001b[1;32mc:\\Users\\adm\\.conda\\envs\\moonshot\\lib\\random.py:378\u001b[0m, in \u001b[0;36mRandom.choice\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Choose a random element from a non-empty sequence.\"\"\"\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;66;03m# raises IndexError if seq is empty\u001b[39;00m\n\u001b[1;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mseq\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_randbelow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "data_dir = Path(r\"D:\\ds_clav_fracture_train_good\\block_0000_anon\")\n",
    "image_paths = list(data_dir.rglob(\"*.dcm\"))  # Рекурсивный поиск DICOM файлов\n",
    "print(f\"Found {len(image_paths)} DICOM files.\")  # Проверяем количество файлов\n",
    "dicom_filepath = random.choice(list((image_paths)))\n",
    "dicom = pydicom.dcmread(dicom_filepath)\n",
    "image = ImageProcessor.preprocess_dicom(dicom)\n",
    "image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moonshot",
   "language": "python",
   "name": "moonshot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
