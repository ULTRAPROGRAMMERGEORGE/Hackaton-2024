{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\GitHub\\Hackaton-2024\\moonshot\\model.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_filepath))\n",
      "C:\\Users\\adm\\AppData\\Local\\Temp\\ipykernel_23596\\3586833233.py:83: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('D:/vision_model.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional, Literal, Callable, Sequence, Any\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import openpyxl\n",
    "cv2.setNumThreads(0)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import os\n",
    "import lightning.pytorch as pl\n",
    "from torchmetrics.classification import (\n",
    "    MultilabelAUROC, MultilabelAveragePrecision\n",
    ")\n",
    "import shutil \n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from lightning.pytorch.utilities.types import OptimizerLRScheduler\n",
    "\n",
    "from torchvision.models.resnet import resnet50\n",
    "\n",
    "from moonshot.model import moonshot\n",
    "from moonshot.image_processor import ImageProcessor\n",
    "from moonshot.utils import eval_mode\n",
    "from pathlib import Path\n",
    "from typing import Callable, Sequence, Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.resnet import resnet50\n",
    "from torchvision.datasets import ImageFolder\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from PIL import UnidentifiedImageError\n",
    "DEVICE = torch.device('cuda')\n",
    "NUM_WORKERS = 16  # поменяйте на кол-во доступных CPU\n",
    "\n",
    "# укажите полный или относительный путь до файла с весами модели Moonshot\n",
    "MOONSHOT_MODEL_FILEPATH = Path('D:/vision_model.pt')  # путь до модели, если она лежит в корне репозитория\n",
    "\n",
    "# --- 1. Настройка устройства ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "VINDRCXR_DIRPATH = Path(r\"D:/l\")\n",
    "image_paths = list(VINDRCXR_DIRPATH.rglob(\"*.dcm\"))\n",
    "file = MOONSHOT_MODEL_FILEPATH\n",
    "class MyModule(nn.Module): \n",
    "      \n",
    "    # Initialize the parameter \n",
    "    def __init__(self, num_inputs, num_outputs, hidden_size): \n",
    "        super(MyModule, self).__init__() \n",
    "        self.linear1 = nn.Linear(num_inputs, hidden_size) \n",
    "        self.linear2 = nn.Linear(hidden_size, num_outputs) \n",
    "      \n",
    "    # Forward pass \n",
    "    def forward(self, input): \n",
    "        lin    = self.linear1(input) \n",
    "        output = nn.functional.relu(lin) \n",
    "        pred   = self.linear2(output) \n",
    "        return pred\n",
    "model = moonshot(MOONSHOT_MODEL_FILEPATH) #\n",
    "model.load_state_dict(torch.load('D:/vision_model.pt')) #мы \n",
    "# load single image or dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DICOMDataset(Dataset):\n",
    "    def __init__(self, image_paths: Sequence[Path], labels: Sequence[int], transform: Optional[Callable] = None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        dicom_file = pydicom.dcmread(str(self.image_paths[idx]))\n",
    "        img = dicom_file.pixel_array\n",
    "        img = cv2.resize(img, (518, 518))  # Преобразуем размер изображения\n",
    "\n",
    "        # Если изображение ч/б, добавим фиктивный канал\n",
    "        if len(img.shape) == 2:\n",
    "            img = np.expand_dims(img, axis=-1)\n",
    "        \n",
    "        # Преобразуем к формату albumentations\n",
    "        img = np.repeat(img, 3, axis=-1).astype(np.uint8)  # Преобразуем в 3 канала\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)[\"image\"]\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "\n",
    "\n",
    "# --- 3. Аугментации ---\n",
    "transform = A.Compose([\n",
    "    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "labels = [0 if \"benign\" in str(p).lower() else 1 for p in image_paths]\n",
    "dataset = DICOMDataset(image_paths, labels, transform)\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, epochs, lr=1e-4):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs).squeeze(1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, epochs=2, lr=1e-4)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moonshot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
